# -*- coding: utf-8 -*-
"""PipeOps â€” CI/CD-focused FastAPI service

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1y1sEyvWd3UiDWmKNrdVAn4E3hqiXSSDK
"""

# ===== PipeOps (FastAPI DevOps microservice) â€” Colab one-cell setup & run =====
# It creates a full project structure under /content/pipeops and starts the server.

import os, textwrap, sys, subprocess, threading, time

PROJECT_ROOT = "/content/pipeops"
os.makedirs(PROJECT_ROOT, exist_ok=True)

# ---------- Helper to write files ----------
def write(path, content):
    full = os.path.join(PROJECT_ROOT, path)
    os.makedirs(os.path.dirname(full), exist_ok=True)
    with open(full, "w", encoding="utf-8") as f:
        f.write(textwrap.dedent(content).lstrip())

# ---------- Project files ----------

# app/main.py
write("app/main.py", r"""
from fastapi import FastAPI, Request
from pydantic import BaseModel
from starlette.responses import Response
from prometheus_client import Counter, Histogram, generate_latest, CONTENT_TYPE_LATEST
import time, os

APP_NAME = os.getenv("APP_NAME", "PipeOps")
app = FastAPI(title=APP_NAME)

# Metrics
REQ_COUNT = Counter("http_requests_total", "Total HTTP requests", ["method", "path", "status"])
LATENCY = Histogram("http_request_duration_seconds", "Request latency seconds", ["method", "path"])

class PipelineRequest(BaseModel):
    repo: str
    branch: str = "main"
    tests: bool = True
    build_image: bool = True

@app.middleware("http")
async def metrics_middleware(request: Request, call_next):
    start = time.time()
    response = await call_next(request)
    LATENCY.labels(request.method, request.url.path).observe(time.time() - start)
    REQ_COUNT.labels(request.method, request.url.path, str(response.status_code)).inc()
    return response

@app.get("/")
def root():
    return {"app": APP_NAME, "message": "CI/CD service online"}

@app.get("/health")
def health():
    return {"status": "ok"}

@app.get("/ready")
def ready():
    return {"ready": True}

@app.get("/metrics")
def metrics():
    return Response(generate_latest(), media_type=CONTENT_TYPE_LATEST)

@app.post("/pipeline/run")
def run_pipeline(req: PipelineRequest):
    # Simulated pipeline steps (swap in real tools later)
    steps = []
    if req.tests:
        steps.append("pytest")
    if req.build_image:
        steps.append("docker build && docker push")
    return {"repo": req.repo, "branch": req.branch, "steps": steps, "status": "queued"}
""")

# tests/test_health.py
write("tests/test_health.py", r"""
from fastapi.testclient import TestClient
from app.main import app

client = TestClient(app)

def test_health():
    r = client.get("/health")
    assert r.status_code == 200
    assert r.json() == {"status": "ok"}
""")

# requirements.txt
write("requirements.txt", r"""
fastapi==0.111.0
uvicorn[standard]==0.30.0
pydantic==1.10.14
prometheus_client==0.20.0
pytest==8.2.1
httpx==0.27.0
""")

# Dockerfile (optional for local/docker use)
write("Dockerfile", r"""
FROM python:3.11-slim
WORKDIR /app
ENV PYTHONDONTWRITEBYTECODE=1 PYTHONUNBUFFERED=1
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt
COPY app ./app
EXPOSE 8080
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8080"]
""")

# .dockerignore
write(".dockerignore", r"""
__pycache__
*.pyc
*.pyo
*.pyd
*.log
.env
.venv
dist
build
.coverage
""")

# .gitignore
write(".gitignore", r"""
__pycache__/
*.py[cod]
.venv/
.env
dist/
build/
.coverage
pytestcache/
*.log
""")

# Makefile (handy if you clone locally)
write("Makefile", r"""
APP?=pipeops
IMAGE?=ghcr.io/$(USER)/$(APP):latest

run:
	uvicorn app.main:app --host 0.0.0.0 --port 8080 --reload

test:
	pytest -q

build:
	docker build -t $(IMAGE) .

push:
	docker push $(IMAGE)
""")

# Minimal README (full detailed one is below in the next block)
write("README.md", r"""
# PipeOps â€” CI/CD-focused FastAPI service

FastAPI service that exposes health/ready/metrics plus a `/pipeline/run` endpoint to simulate CI steps.
See the full README below (in this notebook) for complete instructions.
""")

print("âœ” Project files created at", PROJECT_ROOT)

# ---------- Install dependencies ----------
print("â³ Installing Python dependencies (this runs once per session)...")
subprocess.check_call([sys.executable, "-m", "pip", "install", "-r", os.path.join(PROJECT_ROOT, "requirements.txt")])

# ---------- Run app inside the notebook process ----------
# We run uvicorn programmatically so it doesn't block the Colab UI.
import uvicorn, nest_asyncio
nest_asyncio.apply()

def run_server():
    uvicorn.run("app.main:app", host="0.0.0.0", port=8000, reload=False, app_dir=PROJECT_ROOT, log_level="info")

# Start server in a background thread
server_thread = threading.Thread(target=run_server, daemon=True)
server_thread.start()

# Wait a moment for server to boot
time.sleep(2)

print("\nðŸš€ FastAPI is running in this Colab session.")
print("   Base URL (local to Colab runtime): http://127.0.0.1:8000")
print("   Try a quick check from Python below...")

# Quick self-check using httpx
import httpx
r = httpx.get("http://127.0.0.1:8000/health", timeout=5.0)
print("GET /health ->", r.status_code, r.text)

# Tip: to expose publicly, you can use ngrok (requires account/token) or just test via httpx as above.